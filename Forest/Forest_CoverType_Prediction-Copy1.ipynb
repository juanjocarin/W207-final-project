{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Forest Cover Type Prediction\n",
    "\n",
    "Submitted by:\n",
    "Juanjo Carin, Vamsi Sakhamuri, Tuhin Mahmud\n",
    "\n",
    "Date: July 16, 2015\n",
    "\n",
    "![Linear Combinations](/image/front_page.png)\n",
    "\n",
    "Kaggle Competition hosted at https://www.kaggle.com/c/forest-cover-type-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "### Use cartographic variables to classify forest categories\n",
    "Random forests? Cover trees? Not so fast, computer nerds. We're talking about the real thing.\n",
    "\n",
    "In this competition you are asked to predict the forest cover type (the predominant kind of tree cover) \n",
    "from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type \n",
    "for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information \n",
    "System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. \n",
    "The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables \n",
    "such as wilderness areas and soil type.\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. \n",
    "These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more\n",
    "a result of ecological processes rather than forest management practices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pydot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-58a89bf5c9cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named pydot"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For producing decision tree diagrams.\n",
    "from IPython.core.display import Image, display\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about how to enter a kaggle competition.\n",
    "Frist you sign up for kaggle.\n",
    "\n",
    "https://www.kaggle.com\n",
    "\n",
    "then, you find a competition. We'll use the MNIST digit data set!\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer\n",
    "\n",
    "We now have a couple of csv files, test.csv, and train.csv\n",
    "\n",
    "Find where they live on your file system, and now we need to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(565892L, 55L)\n",
      "(15120L, 55L)\n",
      "(15120L,)\n"
     ]
    }
   ],
   "source": [
    "ff = \"train.csv\" # you will need to edit this directory\n",
    "f = open(ff)\n",
    "column_names = f.readline() # you'd needs this ordinarily\n",
    "\n",
    "data = np.loadtxt(f, delimiter=\",\")\n",
    "\n",
    "y, X = data[:, -1], data[:, :-1]\n",
    "\n",
    "ff_test = \"test.csv\" # you will need to edit this directory\n",
    "f_test = open(ff_test)\n",
    "column_names_test = f_test.readline() # you'd needs this ordinarily\n",
    "\n",
    "data_test = np.loadtxt(f_test, delimiter=\",\")\n",
    "\n",
    "# note there are no labels here!\n",
    "X_test = data_test\n",
    "\n",
    "print X_test.shape\n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  5.  2. ...,  3.  3.  3.]\n"
     ]
    }
   ],
   "source": [
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train a model, let's just do KNN, no time to think!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# to make this faster, just use the first 1000\n",
    "y_train, X_train = y[:1000], X[:1000, :]\n",
    "\n",
    "kn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "kn.fit(X_train, y_train)\n",
    "\n",
    "# here's what we need to send back to Kaggle\n",
    "preds = kn.predict(X_test)\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Decission Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2. ...,  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "preds_dec = dt.predict(X_test)\n",
    "print preds_dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Output results\n",
    "Now we need to save the output to a textfile, and upload the results to kaggle!\n",
    "\n",
    "Read the data page to make you submission the right format:\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_lab_f = open(\"test_labeled.csv\", \"w\") # you will need to edit this directory\n",
    "\n",
    "test_lab_f.write(\"Id,Cover_Type\")\n",
    "\n",
    "idx = X.shape[0]\n",
    "                 \n",
    "for pp in preds_dec:\n",
    "    idx += 1\n",
    "    test_lab_f.write(\"\\n\")\n",
    "    test_lab_f.write(str(idx) + \",\" + str(int(pp)))\n",
    "   \n",
    "\n",
    "test_lab_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "* July 11, 2015 - Simple KNN testing on the data  <a href=\"image/kaggle.result-07-11-2015.png\">  July 11 results score:0.4236 </a>\n",
    "* July 18, 2015 - using Decision Tree on the data  <a href=\"image/kaggle.result-07-18-2015.png\">  July 18 results- score:0.53197</a>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Source Code\n",
    "https://github.com/juanjocarin/W207-final-project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Acknowledgements\n",
    "\n",
    "Kaggle is hosting this competition for the machine learning community to use for fun and practice. \n",
    "This dataset was provided by Jock A. Blackard and Colorado State University. We also thank the UCI machine \n",
    "learning repository for hosting the dataset. If you use the problem in publication, please cite:\n",
    "\n",
    "Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository. Irvine, CA: University of California,\n",
    "    School of Information and Computer Science"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
