{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Cover Type Prediction\n",
    "\n",
    "Submitted by:\n",
    "* Juanjo Carin\n",
    "* Tuhin Mahmud\n",
    "* Vamsi Sakhamuri\n",
    "\n",
    "Date: July 16, 2015\n",
    "\n",
    "Kaggle Competition hosted at https://www.kaggle.com/c/forest-cover-type-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Use cartographic variables to classify forest categories\n",
    "\n",
    "Random forests? Cover trees? Not so fast, computer nerds. We're talking about the real thing.\n",
    "\n",
    "In this competition we are asked to predict the forest cover type (the predominant kind of tree cover) from strictly cartographic variables (as opposed to remotely sensed data). The actual forest cover type for a given 30 x 30 meter cell was determined from US Forest Service (USFS) Region 2 Resource Information System data. Independent variables were then derived from data obtained from the US Geological Survey and USFS. The data is in raw form (not scaled) and contains binary columns of data for qualitative independent variables such as wilderness areas and soil type.\n",
    "\n",
    "This study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the libraries we'll use along this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we load the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test dataset contains 565892 observations with 55 features each.\n",
      "\t(The 1st one is not really a feature but an observation ID.)\n",
      "The training dataset contains 15120 observations with the same 55 features each.\n",
      "For this training set we know the corresponding category (forest cover type) of the 15120 observations.\n"
     ]
    }
   ],
   "source": [
    "ff = \"train.csv\" # you will need to edit this directory\n",
    "f = open(ff)\n",
    "column_names = f.readline() # you'd needs this ordinarily\n",
    "\n",
    "data = np.loadtxt(f, delimiter=\",\")\n",
    "\n",
    "y, X = data[:, -1], data[:, :-1]\n",
    "\n",
    "ff_test = \"test.csv\" # you will need to edit this directory\n",
    "f_test = open(ff_test)\n",
    "column_names_test = f_test.readline() # you'd needs this ordinarily\n",
    "\n",
    "data_test = np.loadtxt(f_test, delimiter=\",\")\n",
    "\n",
    "# note there are no labels here!\n",
    "X_test = data_test\n",
    "\n",
    "print 'The test dataset contains {0} observations with {1} features each.'.format(X_test.shape[0], X_test.shape[1])\n",
    "print '\\t(The 1st one is not really a feature but an observation ID.)'\n",
    "print 'The training dataset contains {0} observations with the same {1} features each.'.format(X.shape[0], X.shape[1])\n",
    "print 'For this training set we know the corresponding category (forest cover type) of the {0} observations.'.format(y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the test set is about 37 times larger than the training set.\n",
    "\n",
    "To evaluate our performance, we'll split the training set in 2 subsets: **training** data (80%) plus **development** (aka **validation**) data (20%). **Test** data *must not* be used to validate our models, otherwise we might introduce bias: the more times we look at the error rate on the test set , the more we know about the test data, and the more we include our knowledge (that's very specific to that test data set) in the way we solve the problem.\n",
    "\n",
    "We also discard the 1st variable (ID), which does not provide any information about the forest cover type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3024L, 54L) (12096L, 54L)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(X.shape[0] * 0.8)\n",
    "y_train, X_train = y[:train_size], X[:train_size, 1:]\n",
    "y_dev, X_dev = y[train_size:], X[train_size:, 1:]\n",
    "X_test = X_test[:, 1:]\n",
    "print X_dev.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 10 features of each observation (`Elevation` to `Horizontal_Distance_To_Fire_Points`) are continuous, with different ranges, while the remaining 44 are all binary.\n",
    "\n",
    "We'll try `preprocessing.StandardScaler` (standardize features by removing the mean and scaling to unit variance) as well as `preprocessing.MinMaxScaler` (standardizes features by scaling each feature to a given range; e.g., [0,1]). We could also try to binarize also those 10 features, using `preprocessing.binarize`, but the appropriate thresholds are unknown.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41137966  0.98333333  0.26923077  0.          0.20857143  0.38955007\n",
      "  0.77165354  0.74193548  0.62903226  0.95002154  1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[-0.18829693  1.80240932 -0.27947559 -1.09616471 -0.83263722  0.66460892\n",
      " -0.55909617 -0.21454597  0.46144063  4.45393267  1.62382295 -0.18155792\n",
      " -0.81629972 -0.64412912 -0.15365563 -0.2026165  -0.2528751  -0.23144494\n",
      " -0.10503856 -0.20829847  0.         -0.00909279 -0.02876462 -0.38973106\n",
      " -0.16056211 -0.1382948  -0.17985039 -0.10544009  0.         -0.08412399\n",
      " -0.19747591 -0.07060485 -0.05760078 -0.10503856 -0.03280079 -0.15167089\n",
      " -0.23733301 -0.13292044 -0.00909279 -0.05831877 -0.03151267 -0.02572573\n",
      "  2.96018781 -0.24310832 -0.14527274 -0.21616885 -0.20678158 -0.03523662\n",
      " -0.07898786 -0.02572573 -0.0445878  -0.21991347 -0.21258268 -0.16954759]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00047020884743512534"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale to range [0,1]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_dev_minmax = min_max_scaler.transform(X_dev)\n",
    "X_test_mimax = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Scale to mean = 0, sd = 1\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "X_train_std = std_scaler.fit_transform(X_train)\n",
    "X_dev_std = std_scaler.transform(X_dev)\n",
    "X_test_std = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data prepared, we start training a very simple kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does our first model perform on the development data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using k = 1 neighbor and non-scaled data: 0.853505291005\n",
      "Accuracy using k = 1 neighbor and standardized data: 0.79828042328\n",
      "Accuracy using k = 1 neighbor and scaled data: 0.812169312169\n"
     ]
    }
   ],
   "source": [
    "kNN.fit(X_train, y_train)\n",
    "print 'Accuracy using k = 1 neighbor and non-scaled data: {0}'.format(kNN.score(X_dev, y_dev))\n",
    "kNN.fit(X_train_std, y_train)\n",
    "print 'Accuracy using k = 1 neighbor and standardized data: {0}'.format(kNN.score(X_dev_std, y_dev))\n",
    "kNN.fit(X_train_minmax, y_train)\n",
    "print 'Accuracy using k = 1 neighbor and scaled data: {0}'.format(kNN.score(X_dev_minmax, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's what we need to send back to Kaggle\n",
    "preds = kNN.predict(X_test)\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'd  need to save the output to a textfile, and upload the results to kaggle (see https://www.kaggle.com/c/digit-recognizer/data for further information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lab_f = open(\"test_labeled.csv\", \"w\") # you will need to edit this directory\n",
    "\n",
    "test_lab_f.write(\"Id,Cover_Type\")\n",
    "\n",
    "idx = X.shape[0]\n",
    "                 \n",
    "for pp in preds:\n",
    "    idx += 1\n",
    "    test_lab_f.write(\"\\n\")\n",
    "    test_lab_f.write(str(idx) + \",\" + str(int(pp)))\n",
    "   \n",
    "test_lab_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
